{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tests the new function for reshaping dtrajs when supplied a n_samples,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from msmbuilder.cluster import NDGrid\n",
    "from pyemma.msm import MaximumLikelihoodMSM\n",
    "from pyemma.coordinates.util import DtrajReshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_X = [np.load('../data/000.5pc/quad_well_00.npy'), np.load('../data/000.5pc/quad_well_01.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_split = []\n",
    "for X in all_X:\n",
    "    for i in range(X.shape[0]-tau):\n",
    "        X_split.append(list(*X[[i,i+tau], :].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_split = np.array(X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split.shape\n",
    "\n",
    "# np.save('split_example.npy', X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90180361,  0.48055044],\n",
       "       [ 0.96266208,  0.48757914],\n",
       "       [ 0.99190124,  0.58029218],\n",
       "       [ 0.90946687,  0.61787998],\n",
       "       [ 0.94062025,  0.58357143]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.60935985,  0.79902993],\n",
       "       [ 0.58011688,  0.76262681],\n",
       "       [ 0.55158962,  0.74071726],\n",
       "       [ 0.54425652,  0.79401891],\n",
       "       [ 0.60790559,  0.76123551]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60935985,  0.58011688,  0.55158962,  0.54425652,  0.60790559,\n",
       "        0.61305799,  0.59323257,  0.64445579,  0.66066766,  0.63381986,\n",
       "        0.64185573,  0.67199441,  0.73598931,  0.73157587,  0.69488388,\n",
       "        0.79248418,  0.87443477,  0.83571034,  0.85276064,  0.87911829,\n",
       "        0.87481689,  0.82992736,  0.83403793,  0.83011021,  0.79484352,\n",
       "        0.79902993,  0.76262681,  0.74071726,  0.79401891,  0.76123551])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_X[-1][-30:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.base import BaseEstimator\n",
    "# from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "# class DtrajReshape(BaseEstimator):\n",
    "#     \"\"\" A template estimator to be used as a reference implementation .\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     demo_param : str, optional\n",
    "#         A parameter used for demonstation of how to pass and store paramters.\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         \"\"\"A reference implementation of a fitting function\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
    "#             The training input samples.\n",
    "#         y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
    "#             The target values (class labels in classification, real numbers in\n",
    "#             regression).\n",
    "#         Returns\n",
    "#         -------\n",
    "#         self : object\n",
    "#             Returns self.\n",
    "#         \"\"\"\n",
    "#         # X, y = check_X_y(X, y)\n",
    "\n",
    "\n",
    "#         # Return the estimator\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         \"\"\" A reference implementation of a predicting function.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like of shape = [n_samples, n_features]\n",
    "#             The input samples.\n",
    "#         Returns\n",
    "#         -------\n",
    "#         y : array of shape = [n_samples]\n",
    "#             Returns :math:`x^2` where :math:`x` is the first column of `X`.\n",
    "#         \"\"\"\n",
    "#         X = check_array(X)\n",
    "#         X_list = [X[i,:].T[:, np.newaxis] for i in range(X.shape[0])]\n",
    "#         return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# traj_paths = glob('data/000.5pc/*.npy')\n",
    "# X = [np.load(traj_path) for traj_path in traj_paths]\n",
    "\n",
    "xmin, xmax = -1.2, 1.2\n",
    "tau = 25\n",
    "\n",
    "model_reshape = Pipeline([('reshape',  DtrajReshape()), \n",
    "                  ('cluster',NDGrid(min=xmin, max=xmax, n_bins_per_feature=200)),\n",
    "                  ('msm', MaximumLikelihoodMSM(lag=1, score_method='vamp1', score_k=3))])\n",
    "\n",
    "model = Pipeline([('cluster',NDGrid(min=xmin, max=xmax, n_bins_per_feature=200)),\n",
    "                  ('msm', MaximumLikelihoodMSM(lag=tau, score_method='vamp1', score_k=3))])\n",
    "\n",
    "param_grid={'cluster__n_bins_per_feature': [100,150,200]}\n",
    "search_reshape = GridSearchCV(model_reshape, param_grid=param_grid, cv=3)\n",
    "search = GridSearchCV(model, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cluster', NDGrid(max=1.2, min=-1.2, n_bins_per_feature=200)), ('msm', MaximumLikelihoodMSM(connectivity='largest', count_mode='sliding',\n",
       "           dt_traj='1 step', lag=25, maxerr=1e-08, maxiter=1000000,\n",
       "           mincount_connectivity='1/n', reversible=True, score_k=3,\n",
       "           score_method='vamp1', sparse=False, statdist_constraint=None))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reshape', DtrajReshape()), ('cluster', NDGrid(max=1.2, min=-1.2, n_bins_per_feature=200)), ('msm', MaximumLikelihoodMSM(connectivity='largest', count_mode='sliding',\n",
       "           dt_traj='1 step', lag=1, maxerr=1e-08, maxiter=1000000,\n",
       "           mincount_connectivity='1/n', reversible=True, score_k=3,\n",
       "           score_method='vamp1', sparse=False, statdist_constraint=None))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reshape.fit(X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('reshape', DtrajReshape()), ('cluster', NDGrid(max=1.2, min=-1.2, n_bins_per_feature=200)), ('msm', MaximumLikelihoodMSM(connectivity='largest', count_mode='sliding',\n",
       "           dt_traj='1 step', lag=1, maxerr=1e-08, maxiter=1000000,\n",
       "           mincount_connectivity='1/n', reversible=True, score_k=3,\n",
       "           score_method='vamp1', sparse=False, statdist_constraint=None))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cluster__n_bins_per_feature': [100, 150, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_reshape.fit(X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/robert_arbon/anaconda/envs/ml4dyn/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(search_reshape.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_cluster__n_bins_per_feature</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>1.325131</td>\n",
       "      <td>1.999357</td>\n",
       "      <td>100</td>\n",
       "      <td>{'cluster__n_bins_per_feature': 100}</td>\n",
       "      <td>2</td>\n",
       "      <td>1.256461</td>\n",
       "      <td>2.062304</td>\n",
       "      <td>1.373406</td>\n",
       "      <td>2.111139</td>\n",
       "      <td>1.346045</td>\n",
       "      <td>1.824627</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.125150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040330</td>\n",
       "      <td>0.040160</td>\n",
       "      <td>1.177056</td>\n",
       "      <td>2.191376</td>\n",
       "      <td>150</td>\n",
       "      <td>{'cluster__n_bins_per_feature': 150}</td>\n",
       "      <td>3</td>\n",
       "      <td>1.093941</td>\n",
       "      <td>2.194015</td>\n",
       "      <td>1.151039</td>\n",
       "      <td>2.313545</td>\n",
       "      <td>1.286820</td>\n",
       "      <td>2.066568</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>0.080903</td>\n",
       "      <td>0.100845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050140</td>\n",
       "      <td>0.034273</td>\n",
       "      <td>1.361903</td>\n",
       "      <td>2.318269</td>\n",
       "      <td>200</td>\n",
       "      <td>{'cluster__n_bins_per_feature': 200}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.185844</td>\n",
       "      <td>2.354765</td>\n",
       "      <td>1.331244</td>\n",
       "      <td>2.423590</td>\n",
       "      <td>1.569954</td>\n",
       "      <td>2.176451</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.158395</td>\n",
       "      <td>0.104142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.044501         0.024255         1.325131          1.999357   \n",
       "1       0.040330         0.040160         1.177056          2.191376   \n",
       "2       0.050140         0.034273         1.361903          2.318269   \n",
       "\n",
       "  param_cluster__n_bins_per_feature                                params  \\\n",
       "0                               100  {'cluster__n_bins_per_feature': 100}   \n",
       "1                               150  {'cluster__n_bins_per_feature': 150}   \n",
       "2                               200  {'cluster__n_bins_per_feature': 200}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                2           1.256461            2.062304           1.373406   \n",
       "1                3           1.093941            2.194015           1.151039   \n",
       "2                1           1.185844            2.354765           1.331244   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            2.111139           1.346045            1.824627      0.008926   \n",
       "1            2.313545           1.286820            2.066568      0.008418   \n",
       "2            2.423590           1.569954            2.176451      0.010812   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.004775        0.050001         0.125150  \n",
       "1        0.026637        0.080903         0.100845  \n",
       "2        0.001630        0.158395         0.104142  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55.74457142,  53.62113347,  43.03708525,  42.20639984])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['msm'].timescales(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55.74457142,  53.62113347,  43.03708525,  42.20639984])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reshape.named_steps['msm'].timescales(k=4)*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
